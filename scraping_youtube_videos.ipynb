{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraping_youtube_videos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXGD16+AvWMd9VRQ48npVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahmoud2571587/Data-Scrapping/blob/main/scraping_youtube_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install libraries need\n",
        "!pip install selenium\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdpQes1mXB6N",
        "outputId": "9e0b3aed-4b47-4f85-a225-f0d387fff35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.3.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.21.0)\n",
            "Requirement already satisfied: urllib3[secure,socks]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.26.10)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (37.0.4)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (22.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (101.0.4951.64-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oYt7Sg36UQl"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import sys\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get page using Chrome webdriver\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "url = 'https://www.youtube.com/c/JohnWatsonRooney/videos?view=0&sort=p&flow=grid'\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "\n",
        "driver.get(url)"
      ],
      "metadata": {
        "id": "oh9zIAGlXLxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract videos data\n",
        "videos = driver.find_elements(by = By.CLASS_NAME , value='style-scope ytd-grid-video-renderer')\n",
        "\n",
        "vid_list =[]\n",
        "for video in videos:\n",
        "  title = video.find_element(by = By.XPATH  , value ='.//*[@id=\"video-title\"]').text\n",
        "  views = video.find_element(by=By.XPATH  , value = './/*[@id=\"metadata-line\"]/span[1]').text\n",
        "  when = video.find_element(by=By.XPATH , value='.//*[@id=\"metadata-line\"]/span[2]').text\n",
        "\n",
        "  vid_items = {'title' : title ,\n",
        "               'views' : views,\n",
        "               'posted' : when}\n",
        "  vid_list.append(vid_items)\n",
        "\n",
        "#store data into dataframe\n",
        "df = pd.DataFrame(vid_list)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "5gpYIgfTdPpw",
        "outputId": "795b8ab0-4686-4166-ce68-cc9772ab1205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                title       views  \\\n",
              "0   Always Check for the Hidden API when Web Scraping  154K views   \n",
              "1   Scrapy for Beginners - A Complete How To Examp...  125K views   \n",
              "2        How to SCRAPE DYNAMIC websites with Selenium   83K views   \n",
              "3   Web Scraping with Python: Ecommerce Product Pa...   76K views   \n",
              "4                   How to Rotate Proxies with Python   62K views   \n",
              "5               Web Scraping: HTML Tables with Python   50K views   \n",
              "6   How to Scrape and Download ALL images from a w...   49K views   \n",
              "7   How I use SELENIUM to AUTOMATE the Web with PY...   41K views   \n",
              "8   How to Web Scrape Indeed with Python - Extract...   41K views   \n",
              "9   How I WEBSCRAPE Websites with LOGINS - Python ...   39K views   \n",
              "10     I Don't Waste Time Parsing HTML (So I do THIS)   38K views   \n",
              "11       How I Scrape JAVASCRIPT websites with Python   37K views   \n",
              "12  How I Scrape multiple pages on Amazon with Pyt...   37K views   \n",
              "13  Beautifulsoup vs Selenium vs Scrapy - Which To...   33K views   \n",
              "14    How to scrape SPORTS STATS websites with Python   32K views   \n",
              "15         Automate Excel Work with Python and Pandas   31K views   \n",
              "16          Scrape Amazon NEW METHOD with Python 2020   31K views   \n",
              "17  How I save my Scraped Data to a Database with ...   27K views   \n",
              "18  How Web Scrape Multiple Pages with ONE Functio...   27K views   \n",
              "19  Render Dynamic Pages - Web Scraping Product Li...   25K views   \n",
              "20  Working With APIs in Python - Pagination and D...   25K views   \n",
              "21                     Python CSV files - with PANDAS   24K views   \n",
              "22         User Agent Switching - Python Web Scraping   24K views   \n",
              "23             Web Scraping NEWS Articles with Python   24K views   \n",
              "24  How to Scrape Stock Prices from Yahoo Finance ...   23K views   \n",
              "25           Python Web Scraping: JSON in SCRIPT tags   23K views   \n",
              "26   Scrape HTML tables easily with Pandas and Python   23K views   \n",
              "27  Crawl and Follow links with SCRAPY - Web Scrap...   22K views   \n",
              "28   Login and Scrape Data with Playwright and Python   22K views   \n",
              "29  How I Scrape Amazon Reviews using Python, Requ...   20K views   \n",
              "\n",
              "           posted  \n",
              "0   11 months ago  \n",
              "1      1 year ago  \n",
              "2     2 years ago  \n",
              "3     2 years ago  \n",
              "4      1 year ago  \n",
              "5     2 years ago  \n",
              "6      1 year ago  \n",
              "7     2 years ago  \n",
              "8      1 year ago  \n",
              "9     2 years ago  \n",
              "10    1 month ago  \n",
              "11    2 years ago  \n",
              "12     1 year ago  \n",
              "13     1 year ago  \n",
              "14     1 year ago  \n",
              "15     1 year ago  \n",
              "16     1 year ago  \n",
              "17     1 year ago  \n",
              "18     1 year ago  \n",
              "19     1 year ago  \n",
              "20     1 year ago  \n",
              "21    2 years ago  \n",
              "22    2 years ago  \n",
              "23     1 year ago  \n",
              "24     1 year ago  \n",
              "25    2 years ago  \n",
              "26     1 year ago  \n",
              "27     1 year ago  \n",
              "28   7 months ago  \n",
              "29     1 year ago  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-023ff9f5-533b-49d9-8c89-a2b0a19dcc07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>views</th>\n",
              "      <th>posted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Always Check for the Hidden API when Web Scraping</td>\n",
              "      <td>154K views</td>\n",
              "      <td>11 months ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Scrapy for Beginners - A Complete How To Examp...</td>\n",
              "      <td>125K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How to SCRAPE DYNAMIC websites with Selenium</td>\n",
              "      <td>83K views</td>\n",
              "      <td>2 years ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Web Scraping with Python: Ecommerce Product Pa...</td>\n",
              "      <td>76K views</td>\n",
              "      <td>2 years ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How to Rotate Proxies with Python</td>\n",
              "      <td>62K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Web Scraping: HTML Tables with Python</td>\n",
              "      <td>50K views</td>\n",
              "      <td>2 years ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How to Scrape and Download ALL images from a w...</td>\n",
              "      <td>49K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How I use SELENIUM to AUTOMATE the Web with PY...</td>\n",
              "      <td>41K views</td>\n",
              "      <td>2 years ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How to Web Scrape Indeed with Python - Extract...</td>\n",
              "      <td>41K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How I WEBSCRAPE Websites with LOGINS - Python ...</td>\n",
              "      <td>39K views</td>\n",
              "      <td>2 years ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>I Don't Waste Time Parsing HTML (So I do THIS)</td>\n",
              "      <td>38K views</td>\n",
              "      <td>1 month ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How I Scrape JAVASCRIPT websites with Python</td>\n",
              "      <td>37K views</td>\n",
              "      <td>2 years ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How I Scrape multiple pages on Amazon with Pyt...</td>\n",
              "      <td>37K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Beautifulsoup vs Selenium vs Scrapy - Which To...</td>\n",
              "      <td>33K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How to scrape SPORTS STATS websites with Python</td>\n",
              "      <td>32K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Automate Excel Work with Python and Pandas</td>\n",
              "      <td>31K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Scrape Amazon NEW METHOD with Python 2020</td>\n",
              "      <td>31K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>How I save my Scraped Data to a Database with ...</td>\n",
              "      <td>27K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>How Web Scrape Multiple Pages with ONE Functio...</td>\n",
              "      <td>27K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Render Dynamic Pages - Web Scraping Product Li...</td>\n",
              "      <td>25K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Working With APIs in Python - Pagination and D...</td>\n",
              "      <td>25K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Python CSV files - with PANDAS</td>\n",
              "      <td>24K views</td>\n",
              "      <td>2 years ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>User Agent Switching - Python Web Scraping</td>\n",
              "      <td>24K views</td>\n",
              "      <td>2 years ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Web Scraping NEWS Articles with Python</td>\n",
              "      <td>24K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>How to Scrape Stock Prices from Yahoo Finance ...</td>\n",
              "      <td>23K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Python Web Scraping: JSON in SCRIPT tags</td>\n",
              "      <td>23K views</td>\n",
              "      <td>2 years ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Scrape HTML tables easily with Pandas and Python</td>\n",
              "      <td>23K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Crawl and Follow links with SCRAPY - Web Scrap...</td>\n",
              "      <td>22K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Login and Scrape Data with Playwright and Python</td>\n",
              "      <td>22K views</td>\n",
              "      <td>7 months ago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>How I Scrape Amazon Reviews using Python, Requ...</td>\n",
              "      <td>20K views</td>\n",
              "      <td>1 year ago</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-023ff9f5-533b-49d9-8c89-a2b0a19dcc07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-023ff9f5-533b-49d9-8c89-a2b0a19dcc07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-023ff9f5-533b-49d9-8c89-a2b0a19dcc07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save data into csv file\n",
        "df.to_csv('youtube_videos.csv')"
      ],
      "metadata": {
        "id": "zXvidSmhkSVI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}